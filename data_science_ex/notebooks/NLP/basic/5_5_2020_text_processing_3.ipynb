{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"\"\"Thomas Jefferson began building Monicello at the age of 26.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Thomas',\n",
       " 'Jefferson',\n",
       " 'began',\n",
       " 'building',\n",
       " 'Monicello',\n",
       " 'at',\n",
       " 'the',\n",
       " 'age',\n",
       " 'of',\n",
       " '26']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern = re.compile(r'([-\\s.,;!?]+)')\n",
    "tokens = pattern.split(sentence)\n",
    "tokens = list(filter(lambda x: x not in '- \\t\\n.,;!?', tokens))\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Quick and dirty n-gram builder method to build n-grams of arbitary size.\n",
    "    \n",
    "\"\"\"\n",
    "def n_gram(tokens, n_gram = 2):\n",
    "    \n",
    "    if n_gram < 1: \n",
    "        raise ArgumentError(\"Can't build n-gram of {}\".format(n_gram))\n",
    "    \n",
    "    if n_gram == 1:\n",
    "        return tokens\n",
    "    \n",
    "    aggregated = []\n",
    "    # Build the actual n-gram\n",
    "    for from_indx in range(len(tokens)):\n",
    "        \n",
    "        if (from_indx + n_gram) > len(tokens):\n",
    "            break\n",
    "\n",
    "        single_n_gram = []\n",
    "        for token_indx in range(from_indx, from_indx + n_gram):\n",
    "            single_n_gram += [tokens[token_indx]]\n",
    "            \n",
    "        aggregated.append(tuple(single_n_gram)) \n",
    "    \n",
    "    return aggregated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Thomas', 'Jefferson'),\n",
       " ('Jefferson', 'began'),\n",
       " ('began', 'building'),\n",
       " ('building', 'Monicello'),\n",
       " ('Monicello', 'at'),\n",
       " ('at', 'the'),\n",
       " ('the', 'age'),\n",
       " ('age', 'of'),\n",
       " ('of', '26')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Building a 2-gram out of the tokens\n",
    "result = n_gram(tokens)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Thomas', 'Jefferson', 'began'),\n",
       " ('Jefferson', 'began', 'building'),\n",
       " ('began', 'building', 'Monicello'),\n",
       " ('building', 'Monicello', 'at'),\n",
       " ('Monicello', 'at', 'the'),\n",
       " ('at', 'the', 'age'),\n",
       " ('the', 'age', 'of'),\n",
       " ('age', 'of', '26')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Building a 3-gram out of the tokens\n",
    "result = n_gram(tokens, 3)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens: 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n-gram > amount of tokens\n",
    "print(\"Number of tokens: {}\".format(len(tokens)))\n",
    "result = n_gram(tokens, 11)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Thomas Jefferson',\n",
       " 'Jefferson began',\n",
       " 'began building',\n",
       " 'building Monicello',\n",
       " 'Monicello at',\n",
       " 'at the',\n",
       " 'the age',\n",
       " 'age of',\n",
       " 'of 26']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n-grams easily joinable\n",
    "[\" \".join(x) for x in n_gram(tokens)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['house', 'fire']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter stop words out of tokens\n",
    "# Depending the library used, the stopwords may differ\n",
    "stop_words = ['a', 'an', 'the', 'on', 'of', 'off', 'this', 'is']\n",
    "tokens = ['the', 'house', 'is', 'on', 'fire']\n",
    "tokens_wa_stop = list(filter(lambda token: token not in stop_words, tokens))\n",
    "tokens_wa_stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring differnt normalization techniques\n",
    "Important to reduce the vocabulary size, thus increasing the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case Folding (case normalization)\n",
    "tokens = ['House', 'Visitor', 'Center']\n",
    "normalized_tokens = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
